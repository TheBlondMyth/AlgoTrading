{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBlondMyth/AlgoTrading/blob/main/NB3.2_Demo_of_Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFDADYvzEh7h"
      },
      "source": [
        "# Demo of convolutional neural network\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This notebook gives an example about the implementation of a simple convolutional neural network. The background context is the same as NB 3.1 where we want to predict the outcomes of the process $$y(t)=\\sin t + \\sin 2t$$ on $t>10$ using the historical observations over $0\\leq t\\leq 10$.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we import some standard packages to being with."
      ],
      "metadata": {
        "id": "d39DoK-L8FtB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS6cSlZCzaGa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating of the time series data\n",
        "\n",
        "We follow the procedures in NB 3.1 to generate the time series data, and then store the results in a pandas dataframe."
      ],
      "metadata": {
        "id": "oBnci-1O-1YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step_size = 0.5 # Each time step in the time series represents 0.5 unit of calendar time\n",
        "\n",
        "t_sample = np.arange(0, 10 + step_size, step_size)\n",
        "t_all = np.arange(0, 20 + step_size, step_size)\n",
        "\n",
        "obs_y = np.sin(t_sample) + np.sin(2*t_sample) # generate the samples\n",
        "true_y = np.sin(t_all) + np.sin(2*t_all)  # generate the true outcomes over the complete time horizon\n",
        "\n",
        "\n",
        "data = pd.DataFrame() # create an empty dataframe variable called \"data\"\n",
        "data['t'] = t_sample # create a column with name 't', put the values from t_sample to this column\n",
        "data['y(t)'] = obs_y # create a column with name 'y(t)', put the values from obs_y to this column\n",
        "\n",
        "display(data) # let's look at what this dataframe is like now"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "4zIpmR5bp0ux",
        "outputId": "91f744d0-c50e-4eb7-950e-2e1b024b88bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2635574f-2a0d-4f4e-adad-cf66ca8a0e91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t</th>\n",
              "      <th>y(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.320897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.750768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1.138615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.152495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.5</td>\n",
              "      <td>-0.360452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.138295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.5</td>\n",
              "      <td>0.306203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.232556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.5</td>\n",
              "      <td>-0.565412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-1.502945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.5</td>\n",
              "      <td>-1.705531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.815988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.635287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.647594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.5</td>\n",
              "      <td>1.588288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.701455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.5</td>\n",
              "      <td>-0.162910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.338869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>9.5</td>\n",
              "      <td>0.074726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.368924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2635574f-2a0d-4f4e-adad-cf66ca8a0e91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2635574f-2a0d-4f4e-adad-cf66ca8a0e91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2635574f-2a0d-4f4e-adad-cf66ca8a0e91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       t      y(t)\n",
              "0    0.0  0.000000\n",
              "1    0.5  1.320897\n",
              "2    1.0  1.750768\n",
              "3    1.5  1.138615\n",
              "4    2.0  0.152495\n",
              "5    2.5 -0.360452\n",
              "6    3.0 -0.138295\n",
              "7    3.5  0.306203\n",
              "8    4.0  0.232556\n",
              "9    4.5 -0.565412\n",
              "10   5.0 -1.502945\n",
              "11   5.5 -1.705531\n",
              "12   6.0 -0.815988\n",
              "13   6.5  0.635287\n",
              "14   7.0  1.647594\n",
              "15   7.5  1.588288\n",
              "16   8.0  0.701455\n",
              "17   8.5 -0.162910\n",
              "18   9.0 -0.338869\n",
              "19   9.5  0.074726\n",
              "20  10.0  0.368924"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structuring of the feature data\n",
        "\n",
        "Unlike NB 3.1 where we are using feedforward neural network (FNN), in this notebook we will try to fit a convolutional neural network (CNN) instead.\n",
        "\n",
        "The key difference between FNN and CNN is that the former takes an input in form of a vector containing all the current and the lagged variables, while the latter takes an input in form of a matrix representing the multivariate time series over a certain window of historical data.\n",
        "\n",
        "The first step is to specify a window width and prepare the input features data. We will use 10 observations as the window width."
      ],
      "metadata": {
        "id": "YULoYDp-_zvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window = 6\n",
        "\n",
        "x_train, y_train = [], []\n",
        "\n",
        "# Loop through the data along the time dimension\n",
        "for i in range(data.shape[0]):\n",
        "\n",
        "    # stop the loop once the index gets out of bound\n",
        "    if i + window > data.shape[0] - 1:\n",
        "        break\n",
        "\n",
        "    # Now we write the values from the dataframe to the x_train and y_train variables\n",
        "\n",
        "    #  WARNING: contrary to usual python slices notation, both the start and the stop are included for pandas dataframe\n",
        "    x_train.append(data.loc[i : i + window - 1, 'y(t)']) # collect the values of y between time i and i+window-1 (our input series)\n",
        "    y_train.append(data.loc[i + window, 'y(t)'])    # collect the value of y at time i+window (our target)\n",
        "\n",
        "# convert the list to numpy array format\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "SzUJyit7Adqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can examine the shape of x_train and y_train as follows. x_train now has a shape of (49989, 10). i.e there are 49989 data points, and each data point carries 10 observations."
      ],
      "metadata": {
        "id": "DtewIOrIBbRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of x_train: \", x_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECEwo8dtBapK",
        "outputId": "c0c77e95-b25f-4041-da52-2104b71efb0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train:  (15, 6)\n",
            "Shape of y_train:  (15,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the input to a CNN has to be a 3D tensor in form of x_train[data index, time point, channel]. In this example, we are working with a univariate time series so there is only one channel. But for our code to work, we must reshape x_train such that it has a shape of (49989, 10, 1). This lets TensorFlow know that we are working with a time series with one channel only.\n",
        "\n",
        "This can be achieved by the \"reshape\" function."
      ],
      "metadata": {
        "id": "0mM8ZXvqypaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "rou_a7_Ayo25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's take a look of the first few data points inside x_train and y_train to confirm that they have the correct values as we expect."
      ],
      "metadata": {
        "id": "znAcKi3LCGUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First data point of x_train\", x_train[0,:,:])\n",
        "print(\"First data point of y_train\", y_train[0])\n",
        "print(\"Second data point of x_train\", x_train[1,:,:])\n",
        "print(\"Second data point of y_train\", y_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCfkKVEmzpAS",
        "outputId": "5511b6df-ff0a-4a7e-8f5a-cfd17fc786cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First data point of x_train [[ 0.        ]\n",
            " [ 1.32089652]\n",
            " [ 1.75076841]\n",
            " [ 1.13861499]\n",
            " [ 0.15249493]\n",
            " [-0.36045213]]\n",
            "First data point of y_train -0.13829549013905865\n",
            "Second data point of x_train [[ 1.32089652]\n",
            " [ 1.75076841]\n",
            " [ 1.13861499]\n",
            " [ 0.15249493]\n",
            " [-0.36045213]\n",
            " [-0.13829549]]\n",
            "Second data point of y_train 0.3062033710291692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a convolutional neural network\n",
        "\n",
        "Now we can proceed to build our convolutional neural network. Let's say we use two convolutional layers. The first one has 4 filters of length 3, and the second one has 8 filters of length 5 (default options for strides and padding). Then we apply global average pooling to collapse the matrix to a vector and pass it to a FNN with one hidden layer with 8 neurons."
      ],
      "metadata": {
        "id": "beLAqroe0Wq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# First convolutional layer\n",
        "model.add(tf.keras.layers.Conv1D(filters=4, kernel_size=3, activation='relu', input_shape=(window, 1))) # each input data has size window*1 as there is one channel only\n",
        "\n",
        "# Second convolutional layer\n",
        "model.add(tf.keras.layers.Conv1D(filters=8, kernel_size=2, activation='relu'))\n",
        "\n",
        "# Global average pooling to collapse the matrix into a vector\n",
        "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "\n",
        "# Dense hidden layer with 8 neurons\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "\n",
        "# Final output layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUNlBkLzKFgP",
        "outputId": "bd58147b-56be-41e2-ed3c-a8dc72868094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 4, 4)              16        \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 3, 8)              72        \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 8)                0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169\n",
            "Trainable params: 169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train the model."
      ],
      "metadata": {
        "id": "-_3DjGDTF1ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mean_squared_error\")\n",
        "model.fit(x_train, y_train, epochs=1000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aQrfFDWF4qw",
        "outputId": "214007f2-c077-45b0-dd0e-6d472ffca788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.9115\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8876\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8735\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8631\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8552\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8490\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8439\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8396\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8359\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8329\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8304\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8283\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8260\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8239\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8220\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8202\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8186\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8169\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8156\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8143\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8131\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8119\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8107\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8095\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8084\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8074\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8065\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8051\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8041\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8032\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8019\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8009\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7998\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7988\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7979\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7962\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7948\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7933\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7919\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7907\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7892\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7881\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7865\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7851\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7839\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7825\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7813\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7797\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7783\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7769\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7756\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7739\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7724\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7710\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7695\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7680\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7661\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7646\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7626\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7611\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7592\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7576\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7557\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7541\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7521\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7503\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7482\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7463\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7443\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7423\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7404\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7386\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7365\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7344\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7325\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7306\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7284\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7266\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7245\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7223\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7203\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7183\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7163\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7142\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7120\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7097\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7077\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7054\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7033\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7013\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6994\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6971\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6950\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6926\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6906\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6885\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6863\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6842\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6823\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6801\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6787\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6761\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6739\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6720\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6699\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6674\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6654\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6631\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6611\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6587\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6567\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6543\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6518\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6496\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6475\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6454\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6425\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6405\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6381\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6360\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6336\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6317\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6291\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6267\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6244\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6222\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6198\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6173\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6152\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6125\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6101\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6076\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6054\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6026\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6004\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5979\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5950\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5921\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5895\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5866\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5838\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5815\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5788\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5758\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5730\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5704\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5678\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5650\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5620\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5592\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5567\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5538\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5511\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5482\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5454\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5425\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5396\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5370\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5340\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5310\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5280\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5251\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5222\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5192\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5159\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5132\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5099\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5074\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5040\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5010\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4983\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4952\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4924\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4891\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4864\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4833\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4802\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4774\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4748\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4714\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4687\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4658\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4627\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4600\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4570\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4541\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4510\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4474\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4448\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4416\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4384\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4353\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4324\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4292\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4263\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4233\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4203\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4174\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4145\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4113\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4086\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4055\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4025\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3999\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3968\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3940\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3910\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3882\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3856\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3828\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3801\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3771\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3742\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3718\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3691\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3664\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3635\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3607\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3584\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3555\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3531\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3502\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3475\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3449\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3424\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3400\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3373\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3346\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3319\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3292\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3264\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3241\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3219\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3196\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3166\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3143\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3115\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3088\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3063\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3042\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3017\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2994\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2971\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2943\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2921\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2894\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2873\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2847\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2821\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2798\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2775\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2750\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2730\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2708\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2689\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2660\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2634\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2613\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2595\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2567\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2548\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2522\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2507\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2479\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2456\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2434\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2419\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2392\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2373\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2347\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2333\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2304\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2281\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2262\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2247\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2223\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2208\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2179\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2166\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2138\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2116\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2098\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2081\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2058\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2044\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2019\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2005\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1978\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1956\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1937\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1917\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1897\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1884\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1856\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1831\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1810\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1792\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1767\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1750\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1723\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1704\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1680\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1667\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1643\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1632\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1605\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1583\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1568\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1555\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1535\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1523\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1498\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1487\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1462\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1446\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1428\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1418\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1396\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1379\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1360\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1351\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1329\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1314\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1297\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1287\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1266\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1258\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1235\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1223\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1204\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1191\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1176\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1163\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1149\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1142\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1122\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1116\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1093\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1078\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1064\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1058\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1039\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1029\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1014\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1003\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0986\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0977\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0961\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0952\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0937\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0931\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0913\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0905\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0888\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0879\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0863\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0850\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0840\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0834\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0822\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0819\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0800\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0791\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0775\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0762\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0751\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0744\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0733\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0731\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0716\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0706\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0695\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0692\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0677\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0667\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0655\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0646\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0637\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0632\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0621\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0613\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0604\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0606\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0591\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0581\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0570\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0561\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0552\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0545\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0537\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0533\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0525\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0518\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0511\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0506\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0497\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0489\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0481\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0477\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0468\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0461\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0453\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0447\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0440\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0434\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0428\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0423\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0418\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0414\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0407\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0401\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0394\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0388\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0382\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0377\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0371\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0366\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0361\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0357\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0353\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0348\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0344\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0340\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0335\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0328\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0323\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0317\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0313\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0309\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0306\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0304\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0301\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0299\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0293\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0287\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0280\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0275\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0270\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0266\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0262\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0259\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0256\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0254\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0253\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0253\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0250\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0246\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0242\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0237\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0232\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0228\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0225\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0221\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0219\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0216\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0214\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0213\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0212\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0211\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0209\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0202\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0198\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0195\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0192\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0189\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0187\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0185\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0184\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0184\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0182\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0182\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0183\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0179\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0174\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0168\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0165\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0163\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0161\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0160\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0160\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0160\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0161\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0164\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0162\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0158\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0155\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0151\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0148\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0145\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0144\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0142\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0143\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0143\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0144\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0146\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0145\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0141\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0136\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0134\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0131\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0130\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0129\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0128\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0128\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0131\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0131\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0130\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0128\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0126\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0123\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0120\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0119\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0117\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0116\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0115\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0116\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0118\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0118\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0119\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0117\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0115\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0113\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0110\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0109\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0110\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0109\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0108\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0107\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0107\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0107\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0106\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0107\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0108\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0107\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0104\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0103\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0103\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0102\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0100\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0099\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0098\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0098\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0100\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0100\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0101\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0100\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0099\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0097\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0095\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0094\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0092\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0093\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0093\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0094\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0096\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0095\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0093\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0090\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0089\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0088\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0087\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0088\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0089\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0091\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0090\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0090\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0089\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0088\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0087\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0084\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0083\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0084\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0084\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0083\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0083\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0085\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0085\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0086\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0084\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0082\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0080\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0079\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0078\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0079\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0079\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0081\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0080\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0080\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0079\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0079\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0078\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0076\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0075\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0074\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0073\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0075\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0076\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0077\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0077\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0077\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0075\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0075\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0073\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0073\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0072\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0070\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0070\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0071\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0071\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0073\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0073\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0074\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0072\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0072\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0070\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0069\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0068\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0069\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0068\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0069\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0069\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0070\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0069\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0070\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0069\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0067\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0066\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0067\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0066\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0067\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0066\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0067\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0066\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0067\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0065\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0066\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0065\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0065\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0064\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0065\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0064\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0065\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0063\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0062\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0063\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0063\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0064\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0064\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0064\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0063\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0061\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0059\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0058\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0058\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0060\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0064\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0063\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0062\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0060\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0061\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0059\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0059\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0057\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0056\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0056\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0057\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0061\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0060\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0062\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0059\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0057\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0057\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0055\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0055\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0054\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0055\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0055\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0056\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0056\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0059\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0058\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0059\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0057\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0058\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0055\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0053\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0052\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0052\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0052\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0053\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0053\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0057\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0058\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0056\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0055\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0053\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0053\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0051\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0051\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0050\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0051\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0053\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0053\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0055\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0054\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0054\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0052\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0051\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0050\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0050\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0050\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0050\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0049\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0050\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0050\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0052\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0052\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0052\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0051\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0051\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0050\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0051\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0049\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0048\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0048\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0048\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0049\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0049\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0049\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0049\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0048\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0048\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0047\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0048\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0048\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0049\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0049\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0048\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0047\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0047\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0045\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0045\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0046\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0046\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0046\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0047\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0047\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0047\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0047\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0047\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0045\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0045\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0045\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0045\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0044\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0044\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0044\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0044\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0045\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0046\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0047\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0046\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0045\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0045\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0044\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0044\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0043\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0042\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0042\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0042\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0043\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0045\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0046\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0046\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0046\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0045\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0043\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0041\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0041\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0041\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0041\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0040\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0041\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0042\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0043\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0044\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0044\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0043\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0043\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0042\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0040\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0039\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0039\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0039\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0040\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0041\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0042\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0044\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0044\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0043\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0042\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0040\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0039\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0038\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0037\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0037\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0037\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0038\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0039\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0041\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0043\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0043\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0043\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0042\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0040\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0039\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0038\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0036\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0036\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0036\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0037\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0039\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0041\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0042\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0042\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0042\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0040\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0038\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0036\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0035\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0034\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0035\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0036\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0038\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0040\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0041\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0041\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0040\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0039\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0035\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0034\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0033\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0034\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0035\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0036\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0038\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0040\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0040\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0040\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0038\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0036\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0034\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0033\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0033\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0033\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0034\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0037\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0038\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0039\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0039\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0037\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0036\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0035\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0034\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0033\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0032\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0035\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0036\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0037\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0036\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0035\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0032\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0032\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0032\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0033\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0035\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0036\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0037\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0037\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0035\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0033\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0032\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0032\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0031\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0031\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0032\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0034\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0035\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0036\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0033\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0032\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0031\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0033\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0034\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0035\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0033\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0032\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0031\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0030\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0030\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0033\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0034\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0033\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0032\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0030\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0030\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0032\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0032\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0032\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0031\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0031\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0031\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0030\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0029\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0030\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0029\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0030\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0031\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0031\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0030\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0031\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0031\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0030\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0030\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0029\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0029\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0029\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0029\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0029\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0030\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0030\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0030\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd94011dd10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model quality\n",
        "\n",
        "With the fitted model, let's try to compute the predictions and compare the results against the actual model values. We perform the prediction and write the results to the dataframe in a new column 'predicted y(t+1)'. The actual true model values are written in the column 'actual y(t+1)'."
      ],
      "metadata": {
        "id": "IAH8445cGfv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['actual y(t+1)'] = data['y(t)'].shift(-1) # create a column containing the true value of the next step\n",
        "data=data.dropna()\n",
        "\n",
        "y_pred = model.predict(x_train) # generate the list of predictions\n",
        "y_pred = y_pred.flatten()       # by default y_pred is some N by 1 matrix. Flatten this to a vector first\n",
        "\n",
        "data.loc[window - 1 :, 'predicted y(t+1)'] = y_pred     #write the predictions to this new column"
      ],
      "metadata": {
        "id": "WXRPODRlGgvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the results."
      ],
      "metadata": {
        "id": "QOGYxN9iBgmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "CwAA9_dkBjDg",
        "outputId": "97a82623-bea3-49d7-f4c5-c893d7a72d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d39d6681-6365-42a0-8237-de63fcde0ffc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t</th>\n",
              "      <th>y(t)</th>\n",
              "      <th>actual y(t+1)</th>\n",
              "      <th>predicted y(t+1)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.320897</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.320897</td>\n",
              "      <td>1.750768</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.750768</td>\n",
              "      <td>1.138615</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1.138615</td>\n",
              "      <td>0.152495</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.152495</td>\n",
              "      <td>-0.360452</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.5</td>\n",
              "      <td>-0.360452</td>\n",
              "      <td>-0.138295</td>\n",
              "      <td>-0.067584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.138295</td>\n",
              "      <td>0.306203</td>\n",
              "      <td>0.385902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.5</td>\n",
              "      <td>0.306203</td>\n",
              "      <td>0.232556</td>\n",
              "      <td>0.254842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.232556</td>\n",
              "      <td>-0.565412</td>\n",
              "      <td>-0.637134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.5</td>\n",
              "      <td>-0.565412</td>\n",
              "      <td>-1.502945</td>\n",
              "      <td>-1.446549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-1.502945</td>\n",
              "      <td>-1.705531</td>\n",
              "      <td>-1.649160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.5</td>\n",
              "      <td>-1.705531</td>\n",
              "      <td>-0.815988</td>\n",
              "      <td>-0.866558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.815988</td>\n",
              "      <td>0.635287</td>\n",
              "      <td>0.681674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.635287</td>\n",
              "      <td>1.647594</td>\n",
              "      <td>1.647398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.647594</td>\n",
              "      <td>1.588288</td>\n",
              "      <td>1.559658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7.5</td>\n",
              "      <td>1.588288</td>\n",
              "      <td>0.701455</td>\n",
              "      <td>0.732059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.701455</td>\n",
              "      <td>-0.162910</td>\n",
              "      <td>-0.065789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.5</td>\n",
              "      <td>-0.162910</td>\n",
              "      <td>-0.338869</td>\n",
              "      <td>-0.346503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.338869</td>\n",
              "      <td>0.074726</td>\n",
              "      <td>0.154375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>9.5</td>\n",
              "      <td>0.074726</td>\n",
              "      <td>0.368924</td>\n",
              "      <td>0.394754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d39d6681-6365-42a0-8237-de63fcde0ffc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d39d6681-6365-42a0-8237-de63fcde0ffc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d39d6681-6365-42a0-8237-de63fcde0ffc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      t      y(t)  actual y(t+1)  predicted y(t+1)\n",
              "0   0.0  0.000000       1.320897               NaN\n",
              "1   0.5  1.320897       1.750768               NaN\n",
              "2   1.0  1.750768       1.138615               NaN\n",
              "3   1.5  1.138615       0.152495               NaN\n",
              "4   2.0  0.152495      -0.360452               NaN\n",
              "5   2.5 -0.360452      -0.138295         -0.067584\n",
              "6   3.0 -0.138295       0.306203          0.385902\n",
              "7   3.5  0.306203       0.232556          0.254842\n",
              "8   4.0  0.232556      -0.565412         -0.637134\n",
              "9   4.5 -0.565412      -1.502945         -1.446549\n",
              "10  5.0 -1.502945      -1.705531         -1.649160\n",
              "11  5.5 -1.705531      -0.815988         -0.866558\n",
              "12  6.0 -0.815988       0.635287          0.681674\n",
              "13  6.5  0.635287       1.647594          1.647398\n",
              "14  7.0  1.647594       1.588288          1.559658\n",
              "15  7.5  1.588288       0.701455          0.732059\n",
              "16  8.0  0.701455      -0.162910         -0.065789\n",
              "17  8.5 -0.162910      -0.338869         -0.346503\n",
              "18  9.0 -0.338869       0.074726          0.154375\n",
              "19  9.5  0.074726       0.368924          0.394754"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The comparison can be visualised on a plot."
      ],
      "metadata": {
        "id": "WXufEVrtS06B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(data['t'], data['predicted y(t+1)'], 'b*', label=\"Predictions of fitted model\")\n",
        "plt.plot(data['t'], data['actual y(t+1)'], 'r--', label=\"True model\")\n",
        "plt.xlabel('t')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "OoIWggbbG6p2",
        "outputId": "a9e843f2-10a0-43fc-a9fd-dff31f90a87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd8ce11f4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflection\n",
        "\n",
        "It should be pointed out that, for this notebook and NB 3.1, the main purpose is just to illustrate the procedures of constructing a neural network model for time series prediction. The fitting quality in general is good, but don't forget we are working with very few number of data points so the good quality here can be an illusion of overfitting.\n",
        "\n",
        "But at least one good news is that our CNN model here actually just has 169 parameters, so perhaps the issue of overfitting is less severe......"
      ],
      "metadata": {
        "id": "FRDZqm-3THSL"
      }
    }
  ]
}